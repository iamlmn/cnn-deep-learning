{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "from os.path import isfile,isdir\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter file already exists!\n"
     ]
    }
   ],
   "source": [
    "vgg_dir = 'F:\\Deeplearning\\deep-learning\\TransferLearningVGG16-FlowerClassification'\n",
    "# Make sure vgg exists\n",
    "#if not isdir(vgg_dir):\n",
    "#    raise Exception(\"VGG directory doesn't exist!\")\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block = 0\n",
    "\n",
    "    def hook(self, block_num=1, block_size=1, total_size=None):\n",
    "        self.total = total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "\n",
    "if not isfile(vgg_dir + \"vgg16.npy\"):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='VGG16 Parameters') as pbar:\n",
    "        urlretrieve(\n",
    "            'https://s3.amazonaws.com/content.udacity-data.com/nd101/vgg16.npy',\n",
    "            vgg_dir + 'vgg16.npy',\n",
    "            pbar.hook)\n",
    "else:\n",
    "    print(\"Parameter file already exists!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flowers Dataset: 229MB [02:49, 1.35MB/s]                                                                               \n"
     ]
    }
   ],
   "source": [
    "# downloading flower dataset from tensorflow\n",
    "\n",
    "import tarfile\n",
    "\n",
    "dataset_folder_path = 'flower_photos'\n",
    "\n",
    "class DLProgress(tqdm):\n",
    "    last_block=0\n",
    "    def hook(self,block_num=1,block_size=1,total_size=None):\n",
    "        self.total=total_size\n",
    "        self.update((block_num - self.last_block) * block_size)\n",
    "        self.last_block = block_num\n",
    "if not isfile('flower_photos.tar.gz'):\n",
    "    with DLProgress(unit='B', unit_scale=True, miniters=1, desc='Flowers Dataset') as pbar:\n",
    "        urlretrieve(\n",
    "            'http://download.tensorflow.org/example_images/flower_photos.tgz',\n",
    "            'flower_photos.tar.gz',\n",
    "            pbar.hook)\n",
    "if not isdir(dataset_folder_path):\n",
    "    with tarfile.open('flower_photos.tar.gz') as tar:\n",
    "        tar.extractall()\n",
    "        tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow_vgg import vgg16\n",
    "from tensorflow_vgg import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flower_photos/'\n",
    "contents = os.listdir(data_dir)\n",
    "classes = [each for each in contents if os.path.isdir(data_dir + each)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F:\\Deeplearning\\deep-learning\\TransferLearningVGG16-FlowerClassification\\tensorflow_vgg\\vgg16.npy\n",
      "npy file loaded\n",
      "build model started\n",
      "build model finished: 6s\n",
      "Starting daisy images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\Anaconda3\\lib\\site-packages\\skimage\\transform\\_warps.py:84: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "codes_list = []\n",
    "labels = []\n",
    "batch = []\n",
    "\n",
    "codes = None\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    vgg=vgg16.Vgg16()\n",
    "    input_=tf.placeholder(tf.float32,[None,224,224,3])\n",
    "    with tf.name_scope(\"content_vgg\"):\n",
    "        vgg.build(input_)\n",
    "        \n",
    "    for each in classes:\n",
    "        print(\"Starting {} images\".format(each))\n",
    "        class_path = data_dir + each\n",
    "        files = os.listdir(class_path)\n",
    "        \n",
    "        for ii, file in enumerate(files, 1):\n",
    "            # Add images to the current batch\n",
    "            # utils.load_image crops the input images for us, from the center\n",
    "            img = utils.load_image(os.path.join(class_path, file))\n",
    "            batch.append(img.reshape((1, 224, 224, 3)))\n",
    "            labels.append(each)\n",
    "        # Running the batch through the network to get the codes\n",
    "        if ii % batch_size == 0 or ii == len(files):\n",
    "            images = np.concatenate(batch)\n",
    "            print(\"Len of images {} at batch {}\".format(len(images),ii))\n",
    "            feed_dict = {input_: images}\n",
    "            codes_batch = sess.run(vgg.relu6, feed_dict=feed_dict)\n",
    "            \n",
    "            # Here I'm building an array of the codes\n",
    "            if codes is None:\n",
    "                codes = codes_batch\n",
    "            else:\n",
    "                codes = np.concatenate((codes, codes_batch))\n",
    "                \n",
    "             # Reset to start building the next batch\n",
    "            batch = []\n",
    "            print('{} images processed'.format(ii))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
