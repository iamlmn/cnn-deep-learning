# deep-learning


## AutoEncoders

>With autoencoders, we pass input data through an encoder that makes a compressed representation of the input. Then, this representation is passed through a decoder to reconstruct the input data. Generally the encoder and decoder will be built with neural networks, then trained on example data.


Reference-arch: 
![alt text][logo]

[logo]: https://github.com/iamlmn/deep-learning/blob/master/AutoEndcoders/simple-ae.JPG "Arch"


### [AutoEncoders with CNN ](https://www.google.com) has improved the performance.
>they can be used to denoise images quite successfully just by training the network on noisy images. We can create the noisy images ourselves by adding Gaussian noise to the training images, then clipping the values to be between 0 and 1. We'll use noisy images as input and the original, clean images as targets
Reference-arch:


![alt text][logo]

[logo]: https://github.com/iamlmn/deep-learning/blob/master/AutoEndcoders/simple-ae.JPG "CNN Arch"

